{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gaveshbhargava/car-sale/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "akcpdR-uZAVO",
        "outputId": "c775bf9e-0746-4a32-e83a-d27c6fc84940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: unknown command \"import\"\n",
            "    YEARS  TATA  MARUTI  HYUNDAI  HONDA   y\n",
            "0    2000    31      32       33     34  no\n",
            "1    2001    32      31       39     38  no\n",
            "2    2002    35      34       33     32  no\n",
            "3    2003    34      33       32     31  no\n",
            "4    2004    37      35       33     31  no\n",
            "5    2005    33      34       35     36  no\n",
            "6    2006    35      33       31     39  no\n",
            "7    2007    31      31       31     31  no\n",
            "8    2008    34      33       32     31  no\n",
            "9    2009    35      32       31     32  no\n",
            "10   2010    33      34       35     36  no\n",
            "11   2011    32      33       34     35  no\n",
            "12   2012    35      32       34     31  no\n",
            "13   2013    37      36       34     35  no\n",
            "14   2014    39      31       32     38  no\n",
            "15   2015    32      34       32     34  no\n",
            "16   2016    35      33       31     37  no\n",
            "17   2017    37      31       35     33  no\n",
            "18   2018    34      34       34     34  no\n",
            "19   2019    34      34       34     34  no\n",
            "20   2020    34      34       34     34  no\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21 entries, 0 to 20\n",
            "Data columns (total 6 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   YEARS    21 non-null     int64 \n",
            " 1   TATA     21 non-null     int64 \n",
            " 2   MARUTI   21 non-null     int64 \n",
            " 3   HYUNDAI  21 non-null     int64 \n",
            " 4   HONDA    21 non-null     int64 \n",
            " 5   y        21 non-null     object\n",
            "dtypes: int64(5), object(1)\n",
            "memory usage: 1.1+ KB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  warnings.warn(SpearmanRConstantInputWarning())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "[0. 0. 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:200: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  warnings.warn(SpearmanRConstantInputWarning())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0 nan nan\n",
            "1.0 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:1001: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
            "  UndefinedMetricWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:1001: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
            "  UndefinedMetricWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 1.0\n",
            "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
            "{'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': True}\n",
            "1.0 1.0\n",
            "ERROR: unknown command \"import\"\n",
            "1.0 1.0\n",
            "1.0 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  var force = true;\n",
              "\n",
              "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
              "    root._bokeh_onload_callbacks = [];\n",
              "    root._bokeh_is_loading = undefined;\n",
              "  }\n",
              "\n",
              "  var JS_MIME_TYPE = 'application/javascript';\n",
              "  var HTML_MIME_TYPE = 'text/html';\n",
              "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
              "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
              "\n",
              "  /**\n",
              "   * Render data to the DOM node\n",
              "   */\n",
              "  function render(props, node) {\n",
              "    var script = document.createElement(\"script\");\n",
              "    node.appendChild(script);\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when an output is cleared or removed\n",
              "   */\n",
              "  function handleClearOutput(event, handle) {\n",
              "    var cell = handle.cell;\n",
              "\n",
              "    var id = cell.output_area._bokeh_element_id;\n",
              "    var server_id = cell.output_area._bokeh_server_id;\n",
              "    // Clean up Bokeh references\n",
              "    if (id != null && id in Bokeh.index) {\n",
              "      Bokeh.index[id].model.document.clear();\n",
              "      delete Bokeh.index[id];\n",
              "    }\n",
              "\n",
              "    if (server_id !== undefined) {\n",
              "      // Clean up Bokeh references\n",
              "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
              "      cell.notebook.kernel.execute(cmd, {\n",
              "        iopub: {\n",
              "          output: function(msg) {\n",
              "            var id = msg.content.text.trim();\n",
              "            if (id in Bokeh.index) {\n",
              "              Bokeh.index[id].model.document.clear();\n",
              "              delete Bokeh.index[id];\n",
              "            }\n",
              "          }\n",
              "        }\n",
              "      });\n",
              "      // Destroy server and session\n",
              "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
              "      cell.notebook.kernel.execute(cmd);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when a new output is added\n",
              "   */\n",
              "  function handleAddOutput(event, handle) {\n",
              "    var output_area = handle.output_area;\n",
              "    var output = handle.output;\n",
              "\n",
              "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
              "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
              "      return\n",
              "    }\n",
              "\n",
              "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
              "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
              "      // store reference to embed id on output_area\n",
              "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "    }\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "      var bk_div = document.createElement(\"div\");\n",
              "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "      var script_attrs = bk_div.children[0].attributes;\n",
              "      for (var i = 0; i < script_attrs.length; i++) {\n",
              "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
              "      }\n",
              "      // store reference to server id on output_area\n",
              "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function register_renderer(events, OutputArea) {\n",
              "\n",
              "    function append_mime(data, metadata, element) {\n",
              "      // create a DOM node to render to\n",
              "      var toinsert = this.create_output_subarea(\n",
              "        metadata,\n",
              "        CLASS_NAME,\n",
              "        EXEC_MIME_TYPE\n",
              "      );\n",
              "      this.keyboard_manager.register_events(toinsert);\n",
              "      // Render to node\n",
              "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "      render(props, toinsert[toinsert.length - 1]);\n",
              "      element.append(toinsert);\n",
              "      return toinsert\n",
              "    }\n",
              "\n",
              "    /* Handle when an output is cleared or removed */\n",
              "    events.on('clear_output.CodeCell', handleClearOutput);\n",
              "    events.on('delete.Cell', handleClearOutput);\n",
              "\n",
              "    /* Handle when a new output is added */\n",
              "    events.on('output_added.OutputArea', handleAddOutput);\n",
              "\n",
              "    /**\n",
              "     * Register the mime type and append_mime function with output_area\n",
              "     */\n",
              "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "      /* Is output safe? */\n",
              "      safe: true,\n",
              "      /* Index of renderer in `output_area.display_order` */\n",
              "      index: 0\n",
              "    });\n",
              "  }\n",
              "\n",
              "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
              "  if (root.Jupyter !== undefined) {\n",
              "    var events = require('base/js/events');\n",
              "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  \n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
              "     \"<div style='background-color: #fdd'>\\n\"+\n",
              "     \"<p>\\n\"+\n",
              "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
              "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
              "     \"</p>\\n\"+\n",
              "     \"<ul>\\n\"+\n",
              "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
              "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
              "     \"</ul>\\n\"+\n",
              "     \"<code>\\n\"+\n",
              "     \"from bokeh.resources import INLINE\\n\"+\n",
              "     \"output_notebook(resources=INLINE)\\n\"+\n",
              "     \"</code>\\n\"+\n",
              "     \"</div>\"}};\n",
              "\n",
              "  function display_loaded() {\n",
              "    var el = document.getElementById(null);\n",
              "    if (el != null) {\n",
              "      el.textContent = \"BokehJS is loading...\";\n",
              "    }\n",
              "    if (root.Bokeh !== undefined) {\n",
              "      if (el != null) {\n",
              "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
              "      }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(display_loaded, 100)\n",
              "    }\n",
              "  }\n",
              "\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
              "        if (callback != null)\n",
              "          callback();\n",
              "      });\n",
              "    } finally {\n",
              "      delete root._bokeh_onload_callbacks\n",
              "    }\n",
              "    console.debug(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(css_urls, js_urls, callback) {\n",
              "    if (css_urls == null) css_urls = [];\n",
              "    if (js_urls == null) js_urls = [];\n",
              "\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls == null || js_urls.length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
              "\n",
              "    function on_load() {\n",
              "      root._bokeh_is_loading--;\n",
              "      if (root._bokeh_is_loading === 0) {\n",
              "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
              "        run_callbacks()\n",
              "      }\n",
              "    }\n",
              "\n",
              "    function on_error(url) {\n",
              "      console.error(\"failed to load \" + url);\n",
              "    }\n",
              "\n",
              "    for (let i = 0; i < css_urls.length; i++) {\n",
              "      const url = css_urls[i];\n",
              "      const element = document.createElement(\"link\");\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error.bind(null, url);\n",
              "      element.rel = \"stylesheet\";\n",
              "      element.type = \"text/css\";\n",
              "      element.href = url;\n",
              "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
              "      document.body.appendChild(element);\n",
              "    }\n",
              "\n",
              "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\": \"dM3QQsP+wXdHg42wTqW85BjZQdLNNIXqlPw/BgKoExPmTG7ZLML4EGqLMfqHT6ON\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\": \"8x57I4YuIfu8XyZfFo0XVr2WAT8EK4rh/uDe3wF7YuW2FNUSNEpJbsPaB1nJ2fz2\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\": \"3QTqdz9LyAm2i0sG5XTePsHec3UHWwVsrOL68SYRoAXsafvfAyqtQ+h440+qIBhS\"};\n",
              "\n",
              "    for (let i = 0; i < js_urls.length; i++) {\n",
              "      const url = js_urls[i];\n",
              "      const element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error.bind(null, url);\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      if (url in hashes) {\n",
              "        element.crossOrigin = \"anonymous\";\n",
              "        element.integrity = \"sha384-\" + hashes[url];\n",
              "      }\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "  };\n",
              "\n",
              "  function inject_raw_css(css) {\n",
              "    const element = document.createElement(\"style\");\n",
              "    element.appendChild(document.createTextNode(css));\n",
              "    document.body.appendChild(element);\n",
              "  }\n",
              "\n",
              "  \n",
              "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\"];\n",
              "  var css_urls = [];\n",
              "  \n",
              "\n",
              "  var inline_js = [\n",
              "    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "    function(Bokeh) {\n",
              "    \n",
              "    \n",
              "    }\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    \n",
              "    if (root.Bokeh !== undefined || force === true) {\n",
              "      \n",
              "    for (var i = 0; i < inline_js.length; i++) {\n",
              "      inline_js[i].call(root, root.Bokeh);\n",
              "    }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    } else if (force !== true) {\n",
              "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
              "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
              "    }\n",
              "\n",
              "  }\n",
              "\n",
              "  if (root._bokeh_is_loading === 0) {\n",
              "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
              "    run_inline_js();\n",
              "  } else {\n",
              "    load_libs(css_urls, js_urls, function() {\n",
              "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "      run_inline_js();\n",
              "    });\n",
              "  }\n",
              "}(window));"
            ],
            "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\": \"dM3QQsP+wXdHg42wTqW85BjZQdLNNIXqlPw/BgKoExPmTG7ZLML4EGqLMfqHT6ON\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\": \"8x57I4YuIfu8XyZfFo0XVr2WAT8EK4rh/uDe3wF7YuW2FNUSNEpJbsPaB1nJ2fz2\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\": \"3QTqdz9LyAm2i0sG5XTePsHec3UHWwVsrOL68SYRoAXsafvfAyqtQ+h440+qIBhS\"};\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "  <div class=\"bk-root\" id=\"d476263a-a895-4105-95ff-93ffc0f487a3\" data-root-id=\"1757\"></div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function embed_document(root) {\n",
              "    \n",
              "  var docs_json = {\"0bb54f0f-c35e-4e04-8615-a651bcd52d34\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1768\"}],\"center\":[{\"id\":\"1771\"},{\"id\":\"1775\"},{\"id\":\"1805\"}],\"left\":[{\"id\":\"1772\"}],\"renderers\":[{\"id\":\"1793\"},{\"id\":\"1810\"}],\"title\":{\"id\":\"1758\"},\"toolbar\":{\"id\":\"1783\"},\"x_range\":{\"id\":\"1760\"},\"x_scale\":{\"id\":\"1764\"},\"y_range\":{\"id\":\"1762\"},\"y_scale\":{\"id\":\"1766\"}},\"id\":\"1757\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"active_multi\":null,\"tools\":[{\"id\":\"1776\"},{\"id\":\"1777\"},{\"id\":\"1778\"},{\"id\":\"1779\"},{\"id\":\"1780\"},{\"id\":\"1781\"}]},\"id\":\"1783\",\"type\":\"Toolbar\"},{\"attributes\":{\"formatter\":{\"id\":\"1800\"},\"major_label_policy\":{\"id\":\"1799\"},\"ticker\":{\"id\":\"1769\"}},\"id\":\"1768\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1882\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1804\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1796\",\"type\":\"AllLabels\"},{\"attributes\":{\"data\":{\"x\":[0,1],\"y\":[0,1]},\"selected\":{\"id\":\"1882\"},\"selection_policy\":{\"id\":\"1883\"}},\"id\":\"1807\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"text\":\"ROC Curve - Train data\"},\"id\":\"1758\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1800\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1803\",\"type\":\"Selection\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#0077bc\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1792\",\"type\":\"Line\"},{\"attributes\":{\"source\":{\"id\":\"1790\"}},\"id\":\"1794\",\"type\":\"CDSView\"},{\"attributes\":{\"formatter\":{\"id\":\"1797\"},\"major_label_policy\":{\"id\":\"1796\"},\"ticker\":{\"id\":\"1773\"}},\"id\":\"1772\",\"type\":\"LinearAxis\"},{\"attributes\":{\"axis\":{\"id\":\"1772\"},\"dimension\":1,\"ticker\":null},\"id\":\"1775\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1781\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"1762\",\"type\":\"DataRange1d\"},{\"attributes\":{\"data\":{\"x\":{\"__ndarray__\":\"AAAAAAAAAAAcx3Ecx3G8PwAAAAAAAPA/\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[3]},\"y\":{\"__ndarray__\":\"AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[3]}},\"selected\":{\"id\":\"1803\"},\"selection_policy\":{\"id\":\"1804\"}},\"id\":\"1790\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"line_color\":\"#d15555\",\"line_dash\":[2,4,6,4],\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1808\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"1883\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1773\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1799\",\"type\":\"AllLabels\"},{\"attributes\":{\"axis\":{\"id\":\"1768\"},\"ticker\":null},\"id\":\"1771\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1779\",\"type\":\"SaveTool\"},{\"attributes\":{\"source\":{\"id\":\"1807\"}},\"id\":\"1811\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1766\",\"type\":\"LinearScale\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#d15555\",\"line_dash\":[2,4,6,4],\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1809\",\"type\":\"Line\"},{\"attributes\":{\"data_source\":{\"id\":\"1790\"},\"glyph\":{\"id\":\"1791\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1792\"},\"view\":{\"id\":\"1794\"}},\"id\":\"1793\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"overlay\":{\"id\":\"1782\"}},\"id\":\"1778\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"label\":{\"value\":\"AUC = nan\"},\"renderers\":[{\"id\":\"1793\"}]},\"id\":\"1806\",\"type\":\"LegendItem\"},{\"attributes\":{},\"id\":\"1797\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1776\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1764\",\"type\":\"LinearScale\"},{\"attributes\":{\"items\":[{\"id\":\"1806\"}]},\"id\":\"1805\",\"type\":\"Legend\"},{\"attributes\":{},\"id\":\"1769\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1777\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"line_color\":\"#0077bc\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1791\",\"type\":\"Line\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"1782\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"1760\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1780\",\"type\":\"ResetTool\"},{\"attributes\":{\"data_source\":{\"id\":\"1807\"},\"glyph\":{\"id\":\"1808\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1809\"},\"view\":{\"id\":\"1811\"}},\"id\":\"1810\",\"type\":\"GlyphRenderer\"}],\"root_ids\":[\"1757\"]},\"title\":\"Bokeh Application\",\"version\":\"2.3.3\"}};\n",
              "  var render_items = [{\"docid\":\"0bb54f0f-c35e-4e04-8615-a651bcd52d34\",\"root_ids\":[\"1757\"],\"roots\":{\"1757\":\"d476263a-a895-4105-95ff-93ffc0f487a3\"}}];\n",
              "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "\n",
              "  }\n",
              "  if (root.Bokeh !== undefined) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (root.Bokeh !== undefined) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else {\n",
              "        attempts++;\n",
              "        if (attempts > 100) {\n",
              "          clearInterval(timer);\n",
              "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
              "        }\n",
              "      }\n",
              "    }, 10, root)\n",
              "  }\n",
              "})(window);"
            ],
            "application/vnd.bokehjs_exec.v0+json": ""
          },
          "metadata": {
            "application/vnd.bokehjs_exec.v0+json": {
              "id": "1757"
            }
          }
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas.core.algorithms as algos\n",
        "from pandas import Series\n",
        "import scipy.stats.stats as stats\n",
        "import re\n",
        "import traceback\n",
        "import string\n",
        "import numpy as np \n",
        "import sklearn\n",
        "import seaborn as sns\n",
        "!pip import sklearn.cross_validation\n",
        "from sklearn import preprocessing\n",
        "from collections import defaultdict\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pandas import DataFrame\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from functools import reduce\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import joblib\n",
        "df = pd.read_excel(\"/Book1.xlsx\")\n",
        "print(df)\n",
        "df.head()\n",
        "df.info()\n",
        "df['target'] = df['y'].apply(lambda x: 1 if x == 'yes' else 0)\n",
        "df.target.value_counts()\n",
        "df.drop('y',axis=1,inplace=True)\n",
        "df.describe()\n",
        "df.dtypes\n",
        "%matplotlib inline\n",
        "corr = df.corr()\n",
        "sns.heatmap(corr,xticklabels=corr.columns,yticklabels=corr.columns)\n",
        "d = defaultdict(preprocessing.LabelEncoder)\n",
        "fit = df.select_dtypes(include=['object']).fillna('NA').apply(lambda x: d[x.name].fit_transform(x))\n",
        "for i in list(d.keys()): \n",
        "  features = df[df.columns.difference(['target'])]\n",
        "labels = df['target']\n",
        "features = features.fillna(0)\n",
        "max_bin = 20\n",
        "force_bin = 3\n",
        "def mono_bin(Y, X, n = max_bin):\n",
        "    df1 = pd.DataFrame({\"X\": X, \"Y\": Y})\n",
        "    justmiss = df1[['X','Y']][df1.X.isnull()]\n",
        "    notmiss = df1[['X','Y']][df1.X.notnull()]\n",
        "    r = 0\n",
        "    while np.abs(r) < 1:\n",
        "        try:\n",
        "            d1 = pd.DataFrame({\"X\": notmiss.X, \"Y\": notmiss.Y, \"Bucket\": pd.qcut(notmiss.X, n)})\n",
        "            d2 = d1.groupby('Bucket', as_index=True)\n",
        "            r, p = stats.spearmanr(d2.mean().X, d2.mean().Y)\n",
        "            n = n - 1 \n",
        "        except Exception as e:\n",
        "            n = n - 1\n",
        "    if len(d2) == 1:\n",
        "        n = force_bin         \n",
        "        bins = algos.quantile(notmiss.X, np.linspace(0, 1, n))\n",
        "        if len(np.unique(bins)) == 2:\n",
        "            bins = np.insert(bins, 0, 1)\n",
        "            bins[1] = bins[1]-(bins[1]/2)\n",
        "        d1 = pd.DataFrame({\"X\": notmiss.X, \"Y\": notmiss.Y, \"Bucket\": pd.cut(notmiss.X, np.unique(bins),include_lowest=True)}) \n",
        "        d2 = d1.groupby('Bucket', as_index=True)\n",
        "    d3 = pd.DataFrame({},index=[])\n",
        "    d3[\"MIN_VALUE\"] = d2.min().X\n",
        "    d3[\"MAX_VALUE\"] = d2.max().X\n",
        "    d3[\"COUNT\"] = d2.count().Y\n",
        "    d3[\"EVENT\"] = d2.sum().Y\n",
        "    d3[\"NONEVENT\"] = d2.count().Y - d2.sum().Y\n",
        "    d3=d3.reset_index(drop=True)\n",
        "    if len(justmiss.index) > 0:\n",
        "        d4 = pd.DataFrame({'MIN_VALUE':np.nan},index=[0])\n",
        "        d4[\"MAX_VALUE\"] = np.nan\n",
        "        d4[\"COUNT\"] = justmiss.count().Y\n",
        "        d4[\"EVENT\"] = justmiss.sum().Y\n",
        "        d4[\"NONEVENT\"] = justmiss.count().Y - justmiss.sum().Y\n",
        "        d3 = d3.append(d4,ignore_index=True)\n",
        "    d3[\"EVENT_RATE\"] = d3.EVENT/d3.COUNT\n",
        "    d3[\"NON_EVENT_RATE\"] = d3.NONEVENT/d3.COUNT\n",
        "    d3[\"DIST_EVENT\"] = d3.EVENT/d3.sum().EVENT\n",
        "    d3[\"DIST_NON_EVENT\"] = d3.NONEVENT/d3.sum().NONEVENT\n",
        "    d3[\"WOE\"] = np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
        "    d3[\"IV\"] = (d3.DIST_EVENT-d3.DIST_NON_EVENT)*np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
        "    d3[\"VAR_NAME\"] = \"VAR\"\n",
        "    d3 = d3[['VAR_NAME','MIN_VALUE', 'MAX_VALUE', 'COUNT', 'EVENT', 'EVENT_RATE', 'NONEVENT', 'NON_EVENT_RATE', 'DIST_EVENT','DIST_NON_EVENT','WOE', 'IV']]       \n",
        "    d3 = d3.replace([np.inf, -np.inf], 0)\n",
        "    d3.IV = d3.IV.sum()\n",
        "    return(d3)\n",
        "def char_bin(Y, X):    \n",
        "    df1 = pd.DataFrame({\"X\": X, \"Y\": Y})\n",
        "    justmiss = df1[['X','Y']][df1.X.isnull()]\n",
        "    notmiss = df1[['X','Y']][df1.X.notnull()]    \n",
        "    df2 = notmiss.groupby('X',as_index=True)\n",
        "    d3 = pd.DataFrame({},index=[])\n",
        "    d3[\"COUNT\"] = df2.count().Y\n",
        "    d3[\"MIN_VALUE\"] = df2.sum().Y.index\n",
        "    d3[\"MAX_VALUE\"] = d3[\"MIN_VALUE\"]\n",
        "    d3[\"EVENT\"] = df2.sum().Y\n",
        "    d3[\"NONEVENT\"] = df2.count().Y - df2.sum().Y\n",
        "    if len(justmiss.index) > 0:\n",
        "        d4 = pd.DataFrame({'MIN_VALUE':np.nan},index=[0])\n",
        "        d4[\"MAX_VALUE\"] = np.nan\n",
        "        d4[\"COUNT\"] = justmiss.count().Y\n",
        "        d4[\"EVENT\"] = justmiss.sum().Y\n",
        "        d4[\"NONEVENT\"] = justmiss.count().Y - justmiss.sum().Y\n",
        "        d3 = d3.append(d4,ignore_index=True)\n",
        "    d3[\"EVENT_RATE\"] = d3.EVENT/d3.COUNT\n",
        "    d3[\"NON_EVENT_RATE\"] = d3.NONEVENT/d3.COUNT\n",
        "    d3[\"DIST_EVENT\"] = d3.EVENT/d3.sum().EVENT\n",
        "    d3[\"DIST_NON_EVENT\"] = d3.NONEVENT/d3.sum().NONEVENT\n",
        "    d3[\"WOE\"] = np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
        "    d3[\"IV\"] = (d3.DIST_EVENT-d3.DIST_NON_EVENT)*np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
        "    d3[\"VAR_NAME\"] = \"VAR\"\n",
        "    d3 = d3[['VAR_NAME','MIN_VALUE', 'MAX_VALUE', 'COUNT', 'EVENT', 'EVENT_RATE', 'NONEVENT', 'NON_EVENT_RATE', 'DIST_EVENT','DIST_NON_EVENT','WOE', 'IV']]      \n",
        "    d3 = d3.replace([np.inf, -np.inf], 0)\n",
        "    d3.IV = d3.IV.sum()\n",
        "    d3 = d3.reset_index(drop=True)\n",
        "    return(d3)\n",
        "def data_vars(df1, target):\n",
        "    stack = traceback.extract_stack()\n",
        "    filename, lineno, function_name, code = stack[-2]\n",
        "    vars_name = re.compile(r'\\((.*?)\\).*$').search(code).groups()[0]\n",
        "    final = (re.findall(r\"[\\w']+\", vars_name))[-1]\n",
        "    x = df1.dtypes.index\n",
        "    count = -1\n",
        "    for i in x:\n",
        "        if i.upper() not in (final.upper()):\n",
        "            if np.issubdtype(df1[i], np.number) and len(Series.unique(df1[i])) > 2:\n",
        "                conv = mono_bin(target, df1[i])\n",
        "                conv[\"VAR_NAME\"] = i\n",
        "                count = count + 1\n",
        "            else:\n",
        "                conv = char_bin(target, df1[i])\n",
        "                conv[\"VAR_NAME\"] = i            \n",
        "                count = count + 1   \n",
        "            if count == 0:\n",
        "                iv_df = conv\n",
        "            else:\n",
        "                iv_df = iv_df.append(conv,ignore_index=True)\n",
        "    iv = pd.DataFrame({'IV':iv_df.groupby('VAR_NAME').IV.max()})\n",
        "    iv = iv.reset_index()\n",
        "    return(iv_df,iv) \n",
        "final_iv, IV = data_vars(df[df.columns.difference(['target'])],df.target)\n",
        "final_iv\n",
        "IV = IV.rename(columns={'VAR_NAME':'index'})\n",
        "IV.sort_values(['IV'],ascending=0)\n",
        "transform_vars_list = df.columns.difference(['target'])\n",
        "transform_prefix = 'new_'\n",
        "transform_vars_list\n",
        "for var in transform_vars_list:\n",
        "    small_df = final_iv[final_iv['VAR_NAME'] == var]\n",
        "    transform_dict = dict(zip(small_df.MAX_VALUE,small_df.WOE))\n",
        "    replace_cmd = ''\n",
        "    replace_cmd1 = ''\n",
        "    for i in sorted(transform_dict.items()):\n",
        "        replace_cmd = replace_cmd + str(i[1]) + str(' if x <= ') + str(i[0]) + ' else '\n",
        "        replace_cmd1 = replace_cmd1 + str(i[1]) + str(' if x == \"') + str(i[0]) + '\" else '\n",
        "    replace_cmd = replace_cmd + '0'\n",
        "    replace_cmd1 = replace_cmd1 + '0'\n",
        "    if replace_cmd != '0':\n",
        "        try:\n",
        "            df[transform_prefix + var] = df[var].apply(lambda x: eval(replace_cmd))\n",
        "        except:\n",
        "            df[transform_prefix + var] = df[var].apply(lambda x: eval(replace_cmd1))\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(features,labels)\n",
        "preds = clf.predict(features)\n",
        "accuracy = accuracy_score(preds,labels)\n",
        "print(accuracy)\n",
        "VI = DataFrame(clf.feature_importances_, columns = [\"RF\"], index=features.columns)\n",
        "VI = VI.reset_index()\n",
        "VI.sort_values(['RF'],ascending=0)\n",
        "model = LogisticRegression()\n",
        "model = ExtraTreesClassifier()\n",
        "model.fit(features, labels)\n",
        "print(model.feature_importances_)\n",
        "FI = DataFrame(model.feature_importances_, columns = [\"Extratrees\"], index=features.columns)\n",
        "FI = FI.reset_index()\n",
        "FI.sort_values(['Extratrees'],ascending=0)\n",
        "model = SelectKBest(score_func=chi2, k=5)\n",
        "fit = model.fit(features.abs(), labels)\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "chi_sq = DataFrame(fit.scores_, columns = [\"Chi_Square\"], index=features.columns)\n",
        "chi_sq = chi_sq.reset_index()\n",
        "chi_sq.sort_values('Chi_Square',ascending=0)\n",
        "dfs = [IV, VI,  FI, chi_sq]\n",
        "final_results = reduce(lambda left,right: pd.merge(left,right,on='index'), dfs)\n",
        "columns = ['IV', 'RF', 'Extratrees', 'Chi_Square']\n",
        "score_table = pd.DataFrame({},[])\n",
        "score_table['index'] = final_results['index']\n",
        "for i in columns:\n",
        "    score_table[i] = final_results['index'].isin(list(final_results.nlargest(5,i)['index'])).astype(int)   \n",
        "score_table['final_score'] = score_table.sum(axis=1)\n",
        "score_table.sort_values('final_score',ascending=0)\n",
        "def calculate_vif(features):\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"Features\"] = features.columns    \n",
        "    return(vif)\n",
        "features = features[list(score_table[score_table['final_score'] >= 2]['index'])]\n",
        "vif = calculate_vif(features)\n",
        "list(vif['Features'])\n",
        "final_vars = list(vif['Features']) + ['target']\n",
        "df1 = df[final_vars].fillna(0)\n",
        "df1.describe()\n",
        "bar_color = '#058caa'\n",
        "num_color = '#ed8549'\n",
        "final_iv,_ = data_vars(df1,df1['target'])\n",
        "final_iv = final_iv[(final_iv.VAR_NAME != 'target')]\n",
        "grouped = final_iv.groupby(['VAR_NAME'])\n",
        "for key, group in grouped:\n",
        "    ax = group.plot('MIN_VALUE','EVENT_RATE',kind='bar',color=bar_color,linewidth=1.0,edgecolor=['black'])\n",
        "    ax.set_title(str(key) + \" vs \" + str('target'))\n",
        "    ax.set_xlabel(key)\n",
        "    ax.set_ylabel(str('target') + \" %\")\n",
        "    rects = ax.patches\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.text(rect.get_x()+rect.get_width()/2., 1.01*height, str(round(height*100,1)) + '%', \n",
        "                ha='center', va='bottom', color=num_color, fontweight='bold')\n",
        "train, test = train_test_split(df1, test_size = 0.4)\n",
        "train = train.reset_index(drop=True)\n",
        "test = test.reset_index(drop=True)\n",
        "features_train = train[list(vif['Features'])]\n",
        "label_train = train['target']\n",
        "features_test = test[list(vif['Features'])]\n",
        "label_test = test['target']\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(features_train,label_train)\n",
        "pred_train = clf.predict(features_train)\n",
        "pred_test = clf.predict(features_test)\n",
        "accuracy_train = accuracy_score(pred_train,label_train)\n",
        "accuracy_test = accuracy_score(pred_test,label_test)\n",
        "from sklearn import metrics\n",
        "print(accuracy_train,accuracy_test)\n",
        "pd.crosstab(label_train,pd.Series(pred_train),rownames=['ACTUAL'],colnames=['PRED'])\n",
        "pd.crosstab(label_test,pd.Series(pred_test),rownames=['ACTUAL'],colnames=['PRED'])\n",
        "clf = LogisticRegression()\n",
        "accuracy_train = accuracy_score(pred_train,label_train)\n",
        "accuracy_test = accuracy_score(pred_test,label_test)\n",
        "print(accuracy_train,accuracy_test)\n",
        "pd.crosstab(label_train,pd.Series(pred_train),rownames=['ACTUAL'],colnames=['PRED'])\n",
        "pd.crosstab(label_test,pd.Series(pred_test),rownames=['ACTUAL'],colnames=['PRED'])\n",
        "clf = MLPClassifier()\n",
        "clf.fit(features_train,label_train)\n",
        "pred_train = clf.predict(features_train)\n",
        "pred_test = clf.predict(features_test)\n",
        "accuracy_train = accuracy_score(pred_train,label_train)\n",
        "accuracy_test = accuracy_score(pred_test,label_test)\n",
        "fpr, tpr, _ = metrics.roc_curve(np.array(label_train), clf.predict_proba(features_train)[:,1])\n",
        "auc_train = metrics.auc(fpr,tpr)\n",
        "fpr, tpr, _ = metrics.roc_curve(np.array(label_test), clf.predict_proba(features_test)[:,1])\n",
        "auc_test = metrics.auc(fpr,tpr)\n",
        "print(accuracy_train,accuracy_test,auc_train,auc_test)\n",
        "pd.crosstab(label_train,pd.Series(pred_train),rownames=['ACTUAL'],colnames=['PRED'])\n",
        "pd.crosstab(label_test,pd.Series(pred_test),rownames=['ACTUAL'],colnames=['PRED'])\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "clf = GaussianNB()\n",
        "clf.fit(features_train,label_train)\n",
        "pred_train = clf.predict(features_train)\n",
        "pred_test = clf.predict(features_test)\n",
        "accuracy_train = accuracy_score(pred_train,label_train)\n",
        "accuracy_test = accuracy_score(pred_test,label_test)\n",
        "print(accuracy_train,accuracy_test)\n",
        "pd.crosstab(label_train,pd.Series(pred_train),rownames=['ACTUAL'],colnames=['PRED'])\n",
        "pd.crosstab(label_test,pd.Series(pred_test),rownames=['ACTUAL'],colnames=['PRED'])\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "clf = GradientBoostingClassifier()\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_train = accuracy_score(pred_train,label_train)\n",
        "accuracy_test = accuracy_score(pred_test,label_test)\n",
        "from sklearn import metrics\n",
        "print(accuracy_train,accuracy_test)\n",
        "pd.crosstab(label_train,pd.Series(pred_train),rownames=['ACTUAL'],colnames=['PRED'])\n",
        "pd.crosstab(label_test,pd.Series(pred_test),rownames=['ACTUAL'],colnames=['PRED'])\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 500, num = 10)]\n",
        "max_features = ['auto', 'sqrt']\n",
        "max_depth = [int(x) for x in np.linspace(3, 10, num = 1)]\n",
        "max_depth.append(None)\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "bootstrap = [True, False]\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "rf = RandomForestClassifier()\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 2, verbose=2, random_state=42, n_jobs = -1)\n",
        "rf_random.fit(features_train, label_train)\n",
        "print(rf_random.best_params_)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(**rf_random.best_params_)\n",
        "clf.fit(features_train,label_train)\n",
        "pred_train = clf.predict(features_train)\n",
        "pred_test = clf.predict(features_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_train = accuracy_score(pred_train,label_train)\n",
        "accuracy_test = accuracy_score(pred_test,label_test)\n",
        "from sklearn import metrics\n",
        "print(accuracy_train,accuracy_test)\n",
        "!pip import cross_validation, metrics\n",
        "from sklearn.model_selection import GridSearchCV,KFold  \n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense,Dropout \n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 500, num = 10)]\n",
        "max_features = ['auto', 'sqrt']\n",
        "max_depth = [int(x) for x in np.linspace(3, 10, num = 1)]\n",
        "max_depth.append(None)\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf}\n",
        "gb = GradientBoostingClassifier()\n",
        "gf_tune = GridSearchCV(estimator = gb, param_grid = grid, cv = 2, verbose=2, n_jobs = -1)\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_train = accuracy_score(pred_train,label_train)\n",
        "accuracy_test = accuracy_score(pred_test,label_test)\n",
        "from sklearn import metrics\n",
        "print(accuracy_train,accuracy_test)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression()\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_train = accuracy_score(pred_train,label_train)\n",
        "accuracy_test = accuracy_score(pred_test,label_test)\n",
        "from sklearn import metrics\n",
        "print(accuracy_train,accuracy_test)\n",
        "pd.crosstab(label_train,pd.Series(pred_train),rownames=['ACTUAL'],colnames=['PRED'])\n",
        "pd.crosstab(label_test,pd.Series(pred_test),rownames=['ACTUAL'],colnames=['PRED'])\n",
        "from ipywidgets import interact\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.io import push_notebook, show, output_notebook\n",
        "output_notebook()\n",
        "from sklearn import metrics\n",
        "auc = metrics.auc(fpr,tpr)\n",
        "p = figure(title=\"ROC Curve - Train data\")\n",
        "r = p.line(fpr,tpr,color='#0077bc',legend = 'AUC = '+ str(round(auc,3)), line_width=2)\n",
        "s = p.line([0,1],[0,1], color= '#d15555',line_dash='dotdash',line_width=2)\n",
        "show(p)\n",
        "from collections import OrderedDict\n",
        "%matplotlib inline\n",
        "def plot_pandas_style(styler):\n",
        "    from IPython.core.display import HTML\n",
        "    html = '\\n'.join([line.lstrip() for line in styler.render().split('\\n')])\n",
        "    return HTML(html)\n",
        "def highlight_max(s,color='yellow'):\n",
        "    is_max = s == s.max()\n",
        "    return ['background-color: {}'.format(color) if v else '' for v in is_max]\n",
        "def decile_labels(agg1,label,color='skyblue'):\n",
        "    agg_dummy = pd.DataFrame(OrderedDict((('TOTAL',0),('TARGET',0),('NONTARGET',0),('PCT_TAR',0),('CUM_TAR',0),('CUM_NONTAR',0),('DIST_TAR',0),('DIST_NONTAR',0),('SPREAD',0))),index=[0])\n",
        "    agg1 = agg1.append(agg_dummy).sort_index()\n",
        "    agg1.index.name = label\n",
        "    agg1 = agg1.style.apply(highlight_max, color = 'yellow', subset=['SPREAD'])\n",
        "    agg1.bar(subset=['TARGET'], color='{}'.format(color))\n",
        "    agg1.bar(subset=['TOTAL'], color='{}'.format(color))\n",
        "    agg1.bar(subset=['PCT_TAR'], color='{}'.format(color))\n",
        "    return(agg1)\n",
        "def deciling(data,decile_by,target,nontarget):\n",
        "    inputs = list(decile_by)\n",
        "    inputs.extend((target,nontarget))\n",
        "    decile = data[inputs]\n",
        "    grouped = decile.groupby(decile_by)\n",
        "    agg1 = pd.DataFrame({},index=[])\n",
        "    agg1['TOTAL'] = grouped.sum()[nontarget] + grouped.sum()[target]\n",
        "    agg1['TARGET'] = grouped.sum()[target]\n",
        "    agg1['NONTARGET'] = grouped.sum()[nontarget]\n",
        "    agg1['PCT_TAR'] = grouped.mean()[target]*100\n",
        "    agg1['CUM_TAR'] = grouped.sum()[target].cumsum()\n",
        "    agg1['CUM_NONTAR'] = grouped.sum()[nontarget].cumsum()\n",
        "    agg1['DIST_TAR'] = agg1['CUM_TAR']/agg1['TARGET'].sum()*100\n",
        "    agg1['DIST_NONTAR'] = agg1['CUM_NONTAR']/agg1['NONTARGET'].sum()*100\n",
        "    agg1['SPREAD'] = (agg1['DIST_TAR'] - agg1['DIST_NONTAR'])\n",
        "    agg1 = decile_labels(agg1,'DECILE',color='skyblue')\n",
        "    return(plot_pandas_style(agg1))\n",
        "from collections import OrderedDict\n",
        "def plots(agg1,target,type):\n",
        "    plt.figure(1,figsize=(20, 5))\n",
        "    plt.subplot(131)\n",
        "    plt.plot(agg1['DECILE'],agg1['ACTUAL'],label='Actual')\n",
        "    plt.plot(agg1['DECILE'],agg1['PRED'],label='Pred')\n",
        "    plt.xticks(range(10,110,10))\n",
        "    plt.legend(fontsize=15)\n",
        "    plt.grid(True)\n",
        "    plt.title('Actual vs Predicted', fontsize=20)\n",
        "    plt.xlabel(\"Population %\",fontsize=15)\n",
        "    plt.ylabel(str(target) + \" \" + str(type) + \" %\",fontsize=15)\n",
        "    plt.subplot(132)\n",
        "    X = agg1['DECILE'].tolist()\n",
        "    X.append(0)\n",
        "    Y = agg1['DIST_TAR'].tolist()\n",
        "    Y.append(0)\n",
        "    plt.plot(sorted(X),sorted(Y))\n",
        "    plt.plot([0, 100], [0, 100],'r--')\n",
        "    plt.xticks(range(0,110,10))\n",
        "    plt.yticks(range(0,110,10))\n",
        "    plt.grid(True)\n",
        "    plt.title('Gains Chart', fontsize=20)\n",
        "    plt.xlabel(\"Population %\",fontsize=15)\n",
        "    plt.ylabel(str(target) + str(\" DISTRIBUTION\") + \" %\",fontsize=15)\n",
        "    plt.annotate(round(agg1[agg1['DECILE'] == 30].DIST_TAR.item(),2),xy=[30,30], \n",
        "            xytext=(25, agg1[agg1['DECILE'] == 30].DIST_TAR.item() + 5),fontsize = 13)\n",
        "    plt.annotate(round(agg1[agg1['DECILE'] == 50].DIST_TAR.item(),2),xy=[50,50], \n",
        "            xytext=(45, agg1[agg1['DECILE'] == 50].DIST_TAR.item() + 5),fontsize = 13)\n",
        "    plt.subplot(133)\n",
        "    plt.plot(agg1['DECILE'],agg1['LIFT'])\n",
        "    plt.xticks(range(10,110,10))\n",
        "    plt.grid(True)\n",
        "    plt.title('Lift Chart', fontsize=20)\n",
        "    plt.xlabel(\"Population %\",fontsize=15)\n",
        "    plt.ylabel(\"Lift\",fontsize=15)\n",
        "    plt.tight_layout()\n",
        "def gains(data,decile_by,target,score):\n",
        "    inputs = list(decile_by)\n",
        "    inputs.extend((target,score))\n",
        "    decile = data[inputs]\n",
        "    grouped = decile.groupby(decile_by)\n",
        "    agg1 = pd.DataFrame({},index=[])\n",
        "    agg1['ACTUAL'] = grouped.mean()[target]*100\n",
        "    agg1['PRED'] = grouped.mean()[score]*100\n",
        "    agg1['DIST_TAR'] = grouped.sum()[target].cumsum()/grouped.sum()[target].sum()*100\n",
        "    agg1.index.name = 'DECILE'\n",
        "    agg1 = agg1.reset_index()\n",
        "    agg1['DECILE'] = agg1['DECILE']*10\n",
        "    agg1['LIFT'] = agg1['DIST_TAR']/agg1['DECILE']\n",
        "    plots(agg1,target,'Distribution')\n",
        "filename = 'final_model.model'\n",
        "i = [d,clf]\n",
        "joblib.dump(i,filename)\n",
        "['final_model.model']\n",
        "filename = 'final_model.model'\n",
        "d,clf=joblib.load(filename)\n",
        "def score_new(features,clf):\n",
        "    score = pd.DataFrame(clf.predict_proba(features)[:,1], columns = ['SCORE'])\n",
        "    score['DECILE'] = pd.qcut(score['SCORE'].rank(method = 'first'),10,labels=range(10,0,-1))\n",
        "    score['DECILE'] = score['DECILE'].astype(float)\n",
        "    return(score)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "mount_file_id": "1z7q_taXPPYyENYw3z0sfWdINOQQgPShs",
      "authorship_tag": "ABX9TyMBzVFneZhsCd1+yQWwgMKz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}